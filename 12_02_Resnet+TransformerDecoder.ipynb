{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.02_Resnet+TransformerDecoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZRh+wE/hbxNIdlP4al7qw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "538f1a745fc54161ba0b51b60e63aae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_382f6ea7a7a846fd9c33be2d4e3b31f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ec7309cf1134093a0d51b3244025898",
              "IPY_MODEL_cd981358a874474fbdf80c06b6f8fda7",
              "IPY_MODEL_beac2e3db6c54e7b83b076d22d6fe7dd"
            ]
          }
        },
        "382f6ea7a7a846fd9c33be2d4e3b31f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ec7309cf1134093a0d51b3244025898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_09c133e354f84c4ab12a473804c6b5ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfa72e5245ba45b985b2d1465a9b8570"
          }
        },
        "cd981358a874474fbdf80c06b6f8fda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6f41e7af6044ac5b8efd6ce5f3639ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88967694db344675a6d4c2388a777b7e"
          }
        },
        "beac2e3db6c54e7b83b076d22d6fe7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea66dc76968f400c8132f1e826d264f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:02&lt;00:00, 32.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_693384d2f32548169b1b5ae612311b00"
          }
        },
        "09c133e354f84c4ab12a473804c6b5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfa72e5245ba45b985b2d1465a9b8570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6f41e7af6044ac5b8efd6ce5f3639ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88967694db344675a6d4c2388a777b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea66dc76968f400c8132f1e826d264f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "693384d2f32548169b1b5ae612311b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64a52b9dec374fbb87b858480482d2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4492f3b2b501416697ace7bae5509b8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9587e47452ec44c8acb2c45171cc1cf8",
              "IPY_MODEL_f2254fb7936f40f48416c726ef54ed13",
              "IPY_MODEL_3515dfcf62bc4077b1009da81aadf5b9"
            ]
          }
        },
        "4492f3b2b501416697ace7bae5509b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9587e47452ec44c8acb2c45171cc1cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_26dbd0418d434577b9e7d75275ca8562",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be2fb5a1733a4702b5f9d11b167c17c0"
          }
        },
        "f2254fb7936f40f48416c726ef54ed13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b846e2cc152f4b8a9f56b286ea2ba86d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7291,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7291,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47f8da29f6014b988f94a757ea46605b"
          }
        },
        "3515dfcf62bc4077b1009da81aadf5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7277f5512e246aeb87ffe4cdd07e250",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7291/7291 [26:12&lt;00:00,  4.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb30f1a5b7ca42ab8009bb5cb810481a"
          }
        },
        "26dbd0418d434577b9e7d75275ca8562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be2fb5a1733a4702b5f9d11b167c17c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b846e2cc152f4b8a9f56b286ea2ba86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47f8da29f6014b988f94a757ea46605b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7277f5512e246aeb87ffe4cdd07e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb30f1a5b7ca42ab8009bb5cb810481a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f39964a267da49f08c00502a03b50605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5bd972dab9de4ec3bc3b2f0dbfbc0993",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_918333b36c894ea6a70e7aafea5c19c7",
              "IPY_MODEL_91309e2651b44f44bdb18b5a8a5bebf7",
              "IPY_MODEL_7345c7a94ad74461a91322bb70b15065"
            ]
          }
        },
        "5bd972dab9de4ec3bc3b2f0dbfbc0993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "918333b36c894ea6a70e7aafea5c19c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3cc044d4a414e44bf0a96435c91d5b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 99%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ddff7c46fe4404da879519ebfb1659a"
          }
        },
        "91309e2651b44f44bdb18b5a8a5bebf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3861e56435fd49bd801a33eff96a4ada",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 811,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 801,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c98299d97aa470b8ba68f0f54ba8a88"
          }
        },
        "7345c7a94ad74461a91322bb70b15065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e31d61221354067beb5af2c469a3a6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 801/811 [00:24&lt;00:00, 32.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d10428c094874c7895b25cf615a3f76f"
          }
        },
        "c3cc044d4a414e44bf0a96435c91d5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ddff7c46fe4404da879519ebfb1659a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3861e56435fd49bd801a33eff96a4ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c98299d97aa470b8ba68f0f54ba8a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e31d61221354067beb5af2c469a3a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d10428c094874c7895b25cf615a3f76f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sooo19/A-study-of-the-data-generation-model-of-the-Folk-Painting-source-data/blob/main/12_02_Resnet%2BTransformerDecoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnpGc4efSrzl"
      },
      "source": [
        "#Image Caption -> ResNet, TransformerDecoder\n",
        "\n",
        "\n",
        "https://www.kaggle.com/dipanjandas96/image-caption-resnet-transformerdecoder-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5QRwIRFS5E9"
      },
      "source": [
        "1. Creating features for Images Using Resnet\n",
        "\n",
        "2. Train Trnasformer Decoder Model which predicts next word given a sequence of tockens and Image Features from Step1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7TryAzT-fs",
        "outputId": "9f2fe7f3-6d61-4ee4-d3c6-cf970f356dff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYZBDnQqwMSb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import gc\n",
        "import random\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsR8gAuJwgKY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "a5cae888-bfd0-43ad-d09c-acb5e3fe66fd"
      },
      "source": [
        "# read data\n",
        "# \"/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/archive/Images\"\n",
        "# \"/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/archive/captions.txt\",\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/t10_archive/captions.txt', sep=',')\n",
        "print(len(df))\n",
        "display(df.head(3)) # 데이터가 제대로 읽어와졌는지 확인하기 위해, 상위 3개 caption 출력.\n",
        "display(df.tail(3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40505\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set of stairs in an entry way .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       image                                                                   caption\n",
              "0  1000268201_693b08cb0e.jpg  A child in a pink dress is climbing up a set of stairs in an entry way .\n",
              "1  1000268201_693b08cb0e.jpg                                     A girl going into a wooden building .\n",
              "2  1000268201_693b08cb0e.jpg                          A little girl climbing into a wooden playhouse ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40502</th>\n",
              "      <td>t10.png</td>\n",
              "      <td>In folk paintings a tiger sits in front of a pine tree .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40503</th>\n",
              "      <td>t10.png</td>\n",
              "      <td>In folk paintings there is a yellow-eyed tiger in folk paintings .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40504</th>\n",
              "      <td>t10.png</td>\n",
              "      <td>In folk paintings there is a pine tree with green leaves in folk paintings .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image                                                                       caption\n",
              "40502  t10.png                      In folk paintings a tiger sits in front of a pine tree .\n",
              "40503  t10.png            In folk paintings there is a yellow-eyed tiger in folk paintings .\n",
              "40504  t10.png  In folk paintings there is a pine tree with green leaves in folk paintings ."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NiZIdaJUQvy"
      },
      "source": [
        "#데이터 전처리\n",
        "Single Character(단일 문자), non alpha word 제거, 토큰과 ',' 추가.\n",
        "모든 캡션의 최대 길이(max_seq_len)는 33으로 맞춰진다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg9145GhUsvF"
      },
      "source": [
        "def remove_single_char_word(word_list):\n",
        "  lst=[]\n",
        "  for word in word_list:\n",
        "    if len(word)>1:\n",
        "      lst.append(word)\n",
        "  return lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPzMzi6oVCMJ",
        "outputId": "f25f3454-46ca-44d5-b2b6-4aed1e0fc950"
      },
      "source": [
        "# <start> < > < > ... < > <end> 형태로 캡션 저장 => 최대 길이: 33\n",
        "df['cleaned_caption']=df['caption'].apply(lambda caption : ['<start>']+[word.lower() if word.isalpha() else '' for word in caption.split(\" \")]+['<end>'])\n",
        "\n",
        "# single character 제거\n",
        "df['cleaned_caption']=df['cleaned_caption'].apply(lambda x:remove_single_char_word(x))\n",
        "\n",
        "# seq_len에 길이 저장 => 33\n",
        "df['seq_len']=df['cleaned_caption'].apply(lambda x:len(x))\n",
        "max_seq_len=df['seq_len'].max()\n",
        "print(max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6V7rUAXGgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "53ddfa34-914b-4a99-f41b-2eab0bd8f87f"
      },
      "source": [
        "df.drop(['seq_len'], axis = 1, inplace=True)\n",
        "df['cleaned_caption']=df['cleaned_caption'].apply(lambda caption: caption+['<pad>']*(max_seq_len-len(caption)))\n",
        "\n",
        "# 상위 3개 데이터 예시 출력\n",
        "display(df.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>cleaned_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set of stairs in an entry way .</td>\n",
              "      <td>[&lt;start&gt;, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>[&lt;start&gt;, girl, going, into, wooden, building, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>[&lt;start&gt;, little, girl, climbing, into, wooden, playhouse, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       image  ...                                                                                                                                                                                                                                   cleaned_caption\n",
              "0  1000268201_693b08cb0e.jpg  ...                            [<start>, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]\n",
              "1  1000268201_693b08cb0e.jpg  ...       [<start>, girl, going, into, wooden, building, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]\n",
              "2  1000268201_693b08cb0e.jpg  ...  [<start>, little, girl, climbing, into, wooden, playhouse, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE3b83z5YQnX"
      },
      "source": [
        "# Create Vocab and mapping of token to ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJIvJtpcYPb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdd7622-06b7-4a82-85db-a4b12b247c63"
      },
      "source": [
        "word_list=df['cleaned_caption'].apply(lambda x: \" \".join(x)).str.cat(sep=' ').split(' ')  \n",
        "#join: , cat(concat): 문자열 합치기. sep=' '에 의해 한 칸씩 뛰고 저장이 된다.\n",
        "word_dict=Counter(word_list)\n",
        "word_dict=sorted(word_dict, key=word_dict.get, reverse=True)\n",
        "\n",
        "print(len(word_dict))\n",
        "print(word_dict[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8366\n",
            "['<pad>', '<start>', '<end>', 'in', 'the', 'on', 'is', 'and', 'dog', 'with', 'man', 'of', 'two', 'white', 'black', 'boy', 'are', 'woman', 'girl', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Le7MdLqZCqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871eeaee-6a9d-49ad-b770-54b4fb479544"
      },
      "source": [
        "vocab_size=len(word_dict)\n",
        "print(vocab_size)\n",
        "\n",
        "index_to_word = {index: word for index, word in enumerate(word_dict)} #enumerate: 반복문에서 index값(몇번째 요소인지)을 출력\n",
        "word_to_index = {word: index for index, word in enumerate(word_dict)}\n",
        "print(len(index_to_word), len(word_to_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8366\n",
            "8366 8366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev_jigPhavcT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEmJhDkawZG"
      },
      "source": [
        "# Convert sequence of tokens to IDs\n",
        "\n",
        "text_seq를 부여함. 단어별로 ID를 부여함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHMQU6sa0am",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "faba4a8c-3e72-454b-caf3-413315d7a2b5"
      },
      "source": [
        "df['text_seq']=df['cleaned_caption'].apply(lambda caption: [word_to_index[word] for word in caption])\n",
        "display(df.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>cleaned_caption</th>\n",
              "      <th>text_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A child in a pink dress is climbing up a set of stairs in an entry way .</td>\n",
              "      <td>[&lt;start&gt;, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "      <td>[1, 41, 3, 89, 168, 6, 118, 52, 392, 11, 389, 3, 27, 5081, 692, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>[&lt;start&gt;, girl, going, into, wooden, building, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "      <td>[1, 18, 312, 63, 193, 116, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>[&lt;start&gt;, little, girl, climbing, into, wooden, playhouse, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
              "      <td>[1, 39, 18, 118, 63, 193, 2406, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       image  ...                                                                                                               text_seq\n",
              "0  1000268201_693b08cb0e.jpg  ...  [1, 41, 3, 89, 168, 6, 118, 52, 392, 11, 389, 3, 27, 5081, 692, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "1  1000268201_693b08cb0e.jpg  ...            [1, 18, 312, 63, 193, 116, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "2  1000268201_693b08cb0e.jpg  ...          [1, 39, 18, 118, 63, 193, 2406, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jcvj_CUbcap"
      },
      "source": [
        "# Split in Train and validation data. \n",
        "(Train과 validation data 나누기) \n",
        "한 데이터가 동시에 training, validation data가 될 수 없음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgrKvDBTb2cT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec88d7e-e883-4745-c00f-25166060635e"
      },
      "source": [
        "df=df.sort_values(by='image')\n",
        "train=df.iloc[:int(0.9*len(df))]  # train과 validation의 비율은 9:1\n",
        "valid=df.iloc[int(0.9*len(df)):]\n",
        "\n",
        "print(len(train), train['image'].nunique()) #nunique() : 데이터에 고유값들의 수를 출력, 즉 중복되는 않은 순 단어의 개수 세기\n",
        "print(len(valid), valid['image'].nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36454 7291\n",
            "4051 811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GahsUZ6c8G3"
      },
      "source": [
        "# Extract features from Images Using Resnet\n",
        "Restnet 구조를 통해 feature 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnACEQHedBtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e374b95a-7f27-4c29-b2f5-da5c6e3f5228"
      },
      "source": [
        "train_samples=len(train)\n",
        "print(train_samples)  # train 길이 출력\n",
        "\n",
        "unq_train_imgs=train[['image']].drop_duplicates() #중복되는 이미지 제거\n",
        "unq_valid_imgs = valid[['image']].drop_duplicates()\n",
        "print(len(unq_train_imgs), len(unq_valid_imgs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36454\n",
            "7291 811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uQhj9YbdHrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd11401-fe5b-4f79-e23b-9338cdd7ae6d"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device) #Cuda 사용"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adgxal3wd7dc"
      },
      "source": [
        "class extractImageFeatureResNetDataSet(): # Resnet 구조를 이용해 이미지의 feature 값들을 추출\n",
        "  def __init__(self, data):\n",
        "    self.data=data\n",
        "    self.scaler=transforms.Resize([224, 224]) # 이미지 크기 재정의\n",
        "    self.normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    self.to_tensor=transforms.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image_name=self.data.iloc[idx]['image']\n",
        "    img_loc=\"/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/t10_archive/Images/\" + str(image_name)\n",
        "    img=Image.open(img_loc)\n",
        "    t_img=self.normalize(self.to_tensor(self.scaler(img)))\n",
        "    return image_name, t_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI0XKLzof_ie"
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYT2KqyqfLQE"
      },
      "source": [
        "train_ImageDataset_ResNet = extractImageFeatureResNetDataSet(unq_train_imgs)  # train 이미지들의 feature를 추출해 저장\n",
        "train_ImageDataloader_ResNet = DataLoader(train_ImageDataset_ResNet, batch_size=1, shuffle=False)\n",
        "\n",
        "valid_ImageDataset_ResNet = extractImageFeatureResNetDataSet(unq_valid_imgs)  # validation 이미지들의 feature를 추출해 저장\n",
        "valid_ImageDataloader_ResNet = DataLoader(valid_ImageDataset_ResNet, batch_size = 1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uF-7rtlgBAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "538f1a745fc54161ba0b51b60e63aae5",
            "382f6ea7a7a846fd9c33be2d4e3b31f5",
            "1ec7309cf1134093a0d51b3244025898",
            "cd981358a874474fbdf80c06b6f8fda7",
            "beac2e3db6c54e7b83b076d22d6fe7dd",
            "09c133e354f84c4ab12a473804c6b5ca",
            "cfa72e5245ba45b985b2d1465a9b8570",
            "b6f41e7af6044ac5b8efd6ce5f3639ea",
            "88967694db344675a6d4c2388a777b7e",
            "ea66dc76968f400c8132f1e826d264f6",
            "693384d2f32548169b1b5ae612311b00"
          ]
        },
        "outputId": "c6589599-9f1b-4095-e5fa-9d71763d32a1"
      },
      "source": [
        "resnet18 = torchvision.models.resnet18(pretrained=True).to(device)\n",
        "resnet18.eval()\n",
        "list(resnet18._modules)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538f1a745fc54161ba0b51b60e63aae5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conv1',\n",
              " 'bn1',\n",
              " 'relu',\n",
              " 'maxpool',\n",
              " 'layer1',\n",
              " 'layer2',\n",
              " 'layer3',\n",
              " 'layer4',\n",
              " 'avgpool',\n",
              " 'fc']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo3e6XEsgpUe"
      },
      "source": [
        "resNet18Layer4 = resnet18._modules.get('layer4').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prefUJ0Fgw-e"
      },
      "source": [
        "def get_vector(t_img):\n",
        "  t_img = Variable(t_img)\n",
        "  my_embedding = torch.zeros(1, 512, 7, 7)  # torch.zeros : 0으로 채워진 텐서 생성\n",
        "  def copy_data(m, i, o):\n",
        "    my_embedding.copy_(o.data)\n",
        "\n",
        "  h = resNet18Layer4.register_forward_hook(copy_data)\n",
        "  resnet18(t_img)\n",
        "\n",
        "  h.remove()\n",
        "  return my_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khxPHMxkI3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914c8bc0-7102-4756-bcb9-15215017fba8"
      },
      "source": [
        "print(\"/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/archive/Images/1000268201_693b08cb0e.jpg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/archive/Images/1000268201_693b08cb0e.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVV-0GxWhhjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "64a52b9dec374fbb87b858480482d2ab",
            "4492f3b2b501416697ace7bae5509b8b",
            "9587e47452ec44c8acb2c45171cc1cf8",
            "f2254fb7936f40f48416c726ef54ed13",
            "3515dfcf62bc4077b1009da81aadf5b9",
            "26dbd0418d434577b9e7d75275ca8562",
            "be2fb5a1733a4702b5f9d11b167c17c0",
            "b846e2cc152f4b8a9f56b286ea2ba86d",
            "47f8da29f6014b988f94a757ea46605b",
            "f7277f5512e246aeb87ffe4cdd07e250",
            "fb30f1a5b7ca42ab8009bb5cb810481a"
          ]
        },
        "outputId": "5abbac8e-db3c-43de-c8be-f000f70152bd"
      },
      "source": [
        "extract_imgFtr_ResNet_train = {}  # train 이미지들의 feature 추출\n",
        "for image_name, t_img in tqdm(train_ImageDataloader_ResNet):   # tqdm: 진행률 프로그래스바\n",
        "  t_img = t_img.to(device)\n",
        "  embdg = get_vector(t_img)\n",
        "\n",
        "  extract_imgFtr_ResNet_train[image_name[0]] = embdg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64a52b9dec374fbb87b858480482d2ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7291 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdYA3GakskPa"
      },
      "source": [
        "a_file = open(\"./EncodedImageTrainResNet.pkl\", \"wb\")\n",
        "pickle.dump(extract_imgFtr_ResNet_train, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufrF_tL6vwOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "f39964a267da49f08c00502a03b50605",
            "5bd972dab9de4ec3bc3b2f0dbfbc0993",
            "918333b36c894ea6a70e7aafea5c19c7",
            "91309e2651b44f44bdb18b5a8a5bebf7",
            "7345c7a94ad74461a91322bb70b15065",
            "c3cc044d4a414e44bf0a96435c91d5b4",
            "8ddff7c46fe4404da879519ebfb1659a",
            "3861e56435fd49bd801a33eff96a4ada",
            "2c98299d97aa470b8ba68f0f54ba8a88",
            "7e31d61221354067beb5af2c469a3a6b",
            "d10428c094874c7895b25cf615a3f76f"
          ]
        },
        "outputId": "7b14cdba-031a-48e8-a3ba-38ca70a7edca"
      },
      "source": [
        "extract_imgFtr_ResNet_valid = {}\n",
        "for image_name, t_img in tqdm(valid_ImageDataloader_ResNet):\n",
        "  t_img = t_img.to(device)\n",
        "  embdg = get_vector(t_img)\n",
        "  extract_imgFtr_ResNet_valid[image_name[0]] = embdg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f39964a267da49f08c00502a03b50605",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/811 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-02e0233e2ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mextract_imgFtr_ResNet_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_img\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ImageDataloader_ResNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0membdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mextract_imgFtr_ResNet_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membdg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-2f2b69d4250a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/t10_archive/Images/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mt_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh2T2LZgxPzz"
      },
      "source": [
        "a_file=open(\"./EncodedImageValidResNet.pkl\", \"wb\")\n",
        "pickle.dump(extract_imgFtr_ResNet_valid, a_file)\n",
        "a_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZ_ZNcfxemo"
      },
      "source": [
        "#Create DataLoader which will be used to load data into Transformer Model\n",
        "Transformer 모델에 데이터를 load하는데 사용할 dataloader을 생성\n",
        "\n",
        "(FlickerDataSetResnet will return caption sequence, 1 timestep left shifted caption sequence which model will predict and Stored Image features from ResNet.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKLrsjISxsAb"
      },
      "source": [
        "global image_tensor_view\n",
        "\n",
        "class FlickerDataSetResnet():\n",
        "  def __init__(self, data, pkl_file):\n",
        "    self.data=data\n",
        "    self.encodedImgs = pd.read_pickle(pkl_file)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    caption_seq = self.data.iloc[idx]['text_seq']\n",
        "    target_seq = caption_seq[1:]+[0]\n",
        "\n",
        "    image_name = self.data.iloc[idx]['image']\n",
        "    image_tensor = self.encodedImgs[image_name]\n",
        "    image_tensor = image_tensor.permute(0,2,3,1)  # tensor의 모양을 변환. permute는 모든 차원을 교환할 수 있음.\n",
        "    image_tensor_view = image_tensor.view(image_tensor.size(0), -1, image_tensor.size(3))\n",
        "    return torch.tensor(caption_seq), torch.tensor(target_seq), image_tensor_view"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b68OlBBkzeVv"
      },
      "source": [
        "train_dataset_resnet = FlickerDataSetResnet(train, 'EncodedImageTrainResNet.pkl')\n",
        "train_dataloader_resnet = DataLoader(train_dataset_resnet, batch_size = 32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk7ZnrRTzyDE"
      },
      "source": [
        "valid_dataset_resnet = FlickerDataSetResnet(valid, 'EncodedImageValidResNet.pkl')\n",
        "valid_dataloader_resnet = DataLoader(valid_dataset_resnet, batch_size = 32, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85d1uNFUz9U9"
      },
      "source": [
        "#Create Transformer Decoder Model\n",
        "This model will take caption sequence and the extracted resnet image features as input and output 1 timestep shifted caption sequence.\n",
        "\n",
        "In the Transformer decoder, lookAhead and padding mask has also been applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3foX7DT_0Mc5"
      },
      "source": [
        "# Position Embedding\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=max_seq_len):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pe.size(0) < x.size(0):\n",
        "            self.pe = self.pe.repeat(x.size(0), 1, 1).to(device)\n",
        "        self.pe = self.pe[:x.size(0), : , : ]\n",
        "        \n",
        "        x = x + self.pe\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr6e9zrI06pX"
      },
      "source": [
        "# Image Captioning Model\n",
        "# Transformer Decoder\n",
        "\n",
        "class ImageCaptionModel(nn.Module):\n",
        "    def __init__(self, n_head, n_decoder_layer, vocab_size, embedding_size):\n",
        "        super(ImageCaptionModel, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(embedding_size, 0.1)\n",
        "        self.TransformerDecoderLayer = nn.TransformerDecoderLayer(d_model =  embedding_size, nhead = n_head)\n",
        "        self.TransformerDecoder = nn.TransformerDecoder(decoder_layer = self.TransformerDecoderLayer, num_layers = n_decoder_layer)\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(vocab_size , embedding_size)\n",
        "        self.last_linear_layer = nn.Linear(embedding_size, vocab_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.last_linear_layer.bias.data.zero_()\n",
        "        self.last_linear_layer.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def generate_Mask(self, size, decoder_inp):\n",
        "        decoder_input_mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "        decoder_input_mask = decoder_input_mask.float().masked_fill(decoder_input_mask == 0, float('-inf')).masked_fill(decoder_input_mask == 1, float(0.0))\n",
        "\n",
        "        decoder_input_pad_mask = decoder_inp.float().masked_fill(decoder_inp == 0, float(0.0)).masked_fill(decoder_inp > 0, float(1.0))\n",
        "        decoder_input_pad_mask_bool = decoder_inp == 0\n",
        "\n",
        "        return decoder_input_mask, decoder_input_pad_mask, decoder_input_pad_mask_bool\n",
        "\n",
        "    def forward(self, encoded_image, decoder_inp):\n",
        "        encoded_image = encoded_image.permute(1,0,2)\n",
        "        \n",
        "\n",
        "        decoder_inp_embed = self.embedding(decoder_inp)* math.sqrt(self.embedding_size)\n",
        "        \n",
        "        decoder_inp_embed = self.pos_encoder(decoder_inp_embed)\n",
        "        decoder_inp_embed = decoder_inp_embed.permute(1,0,2)\n",
        "        \n",
        "\n",
        "        decoder_input_mask, decoder_input_pad_mask, decoder_input_pad_mask_bool = self.generate_Mask(decoder_inp.size(1), decoder_inp)\n",
        "        decoder_input_mask = decoder_input_mask.to(device)\n",
        "        decoder_input_pad_mask = decoder_input_pad_mask.to(device)\n",
        "        decoder_input_pad_mask_bool = decoder_input_pad_mask_bool.to(device)\n",
        "        \n",
        "\n",
        "        decoder_output = self.TransformerDecoder(tgt = decoder_inp_embed, memory = encoded_image, tgt_mask = decoder_input_mask, tgt_key_padding_mask = decoder_input_pad_mask_bool)\n",
        "        \n",
        "        final_output = self.last_linear_layer(decoder_output)\n",
        "\n",
        "        return final_output,  decoder_input_pad_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8tB5zB-1q6y"
      },
      "source": [
        "#Train the Model\n",
        "\n",
        "The cross entropy loss has been masked at time steps where input token is <'pad'>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4q6WfLi1spY"
      },
      "source": [
        "EPOCH = 30\n",
        "#EPOCH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6CVlkLv1_IM"
      },
      "source": [
        "ictModel = ImageCaptionModel(16, 4, vocab_size, 512).to(device)\n",
        "optimizer = torch.optim.Adam(ictModel.parameters(), lr = 0.00001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience=2, verbose=True)\n",
        "criterion=torch.nn.CrossEntropyLoss(reduction='none')\n",
        "min_val_loss=np.float('Inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSFa1zkW2cBc"
      },
      "source": [
        "for epoch in tqdm(range(EPOCH)):\n",
        "    total_epoch_train_loss = 0\n",
        "    total_epoch_valid_loss = 0\n",
        "    total_train_words = 0\n",
        "    total_valid_words = 0\n",
        "    ictModel.train()\n",
        "\n",
        "    ### Train Loop\n",
        "    for caption_seq, target_seq, image_embed in train_dataloader_resnet:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        image_embed = image_embed.squeeze(1).to(device)\n",
        "        caption_seq = caption_seq.to(device)\n",
        "        target_seq = target_seq.to(device)\n",
        "\n",
        "        output, padding_mask = ictModel.forward(image_embed, caption_seq)\n",
        "        output = output.permute(1, 2, 0)\n",
        "\n",
        "        loss = criterion(output,target_seq)\n",
        "\n",
        "        loss_masked = torch.mul(loss, padding_mask)\n",
        "\n",
        "        final_batch_loss = torch.sum(loss_masked)/torch.sum(padding_mask)\n",
        "\n",
        "        final_batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_epoch_train_loss += torch.sum(loss_masked).detach().item()\n",
        "        total_train_words += torch.sum(padding_mask)\n",
        "\n",
        " \n",
        "    total_epoch_train_loss = total_epoch_train_loss/total_train_words\n",
        "  \n",
        "\n",
        "    ### Eval Loop\n",
        "    ictModel.eval()\n",
        "    with torch.no_grad():\n",
        "        for caption_seq, target_seq, image_embed in valid_dataloader_resnet:\n",
        "\n",
        "            image_embed = image_embed.squeeze(1).to(device)\n",
        "            caption_seq = caption_seq.to(device)\n",
        "            target_seq = target_seq.to(device)\n",
        "\n",
        "            output, padding_mask = ictModel.forward(image_embed, caption_seq)\n",
        "            output = output.permute(1, 2, 0)\n",
        "\n",
        "            loss = criterion(output,target_seq)\n",
        "\n",
        "            loss_masked = torch.mul(loss, padding_mask)\n",
        "\n",
        "            total_epoch_valid_loss += torch.sum(loss_masked).detach().item()\n",
        "            total_valid_words += torch.sum(padding_mask)\n",
        "\n",
        "    total_epoch_valid_loss = total_epoch_valid_loss/total_valid_words\n",
        "  \n",
        "    print(\"Epoch -> \", epoch,\" Training Loss -> \", total_epoch_train_loss.item(), \"Eval Loss -> \", total_epoch_valid_loss.item() )\n",
        "  \n",
        "    if min_val_loss > total_epoch_valid_loss:\n",
        "        print(\"Writing Model at epoch \", epoch)\n",
        "        torch.save(ictModel, './BestModel')\n",
        "        min_val_loss = total_epoch_valid_loss\n",
        "  \n",
        "\n",
        "    scheduler.step(total_epoch_valid_loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvnXbZkoPBr-"
      },
      "source": [
        "#Generate Captions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyRvVnuRPDxK"
      },
      "source": [
        "model = torch.load('./BestModel')\n",
        "start_token = word_to_index['<start>']\n",
        "end_token = word_to_index['<end>']\n",
        "pad_token = word_to_index['<pad>']\n",
        "max_seq_len = 33\n",
        "print(start_token, end_token, pad_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APAiU6mRPKlQ"
      },
      "source": [
        "valid_img_embed = pd.read_pickle('EncodedImageValidResNet.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE5h8elhPNB_"
      },
      "source": [
        "def generate_caption(K, img_nm): \n",
        "    img_loc = '/content/gdrive/MyDrive/Colab Notebooks/Folk Painting Source Data/archive/Images/'+str(img_nm)\n",
        "    image = Image.open(img_loc).convert(\"RGB\")\n",
        "    plt.imshow(image)\n",
        "\n",
        "    model.eval() \n",
        "    valid_img_df = valid[valid['image']==img_nm]\n",
        "    print(\"Actual Caption : \")\n",
        "    print(valid_img_df['caption'].tolist())\n",
        "    img_embed = valid_img_embed[img_nm].to(device)\n",
        "\n",
        "\n",
        "    img_embed = img_embed.permute(0,2,3,1)\n",
        "    img_embed = img_embed.view(img_embed.size(0), -1, img_embed.size(3))\n",
        "\n",
        "\n",
        "    input_seq = [pad_token]*max_seq_len\n",
        "    input_seq[0] = start_token\n",
        "\n",
        "    input_seq = torch.tensor(input_seq).unsqueeze(0).to(device)\n",
        "    predicted_sentence = []\n",
        "    with torch.no_grad():\n",
        "        for eval_iter in range(0, max_seq_len):\n",
        "\n",
        "            output, padding_mask = model.forward(img_embed, input_seq)\n",
        "\n",
        "            output = output[eval_iter, 0, :]\n",
        "\n",
        "            values = torch.topk(output, K).values.tolist()\n",
        "            indices = torch.topk(output, K).indices.tolist()\n",
        "\n",
        "            next_word_index = random.choices(indices, values, k = 1)[0]\n",
        "\n",
        "            next_word = index_to_word[next_word_index]\n",
        "\n",
        "            input_seq[:, eval_iter+1] = next_word_index\n",
        "\n",
        "\n",
        "            if next_word == '<end>' :\n",
        "                break\n",
        "\n",
        "            predicted_sentence.append(next_word)\n",
        "    print(\"\\n\")\n",
        "    print(\"Predicted caption : \")\n",
        "    print(\" \".join(predicted_sentence+['.']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEG_SyN3W2tf"
      },
      "source": [
        "generate_caption(1, unq_valid_imgs.iloc[50]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_XruoAfXBn2"
      },
      "source": [
        "#generate_caption(2, unq_valid_imgs.iloc[50]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USKgq1I_XD7R"
      },
      "source": [
        "#generate_caption(3, unq_valid_imgs.iloc[50]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl8bGHe4aERw"
      },
      "source": [
        "#generate_caption(4, unq_valid_imgs.iloc[50]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5uPVac6aEbE"
      },
      "source": [
        "#generate_caption(5, unq_valid_imgs.iloc[50]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0RcDAiQYY94"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[5]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaGPtrAiYpaw"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[10]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDU-lWy4Yr3y"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[15]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTUq40FYtnk"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[20]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3wZ4pwLYwFH"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[25]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcoZTnIYwdc"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[30]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfvsoCCVYylw"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[35]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjnfxCukYz6L"
      },
      "source": [
        "#generate_caption(1, unq_valid_imgs.iloc[40]['image'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk8i6yXCYyuD"
      },
      "source": [
        "#generate_caption(31, unq_valid_imgs.iloc[45]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc5jI_zdQxa4"
      },
      "source": [
        "'''\n",
        "for j in range(1, 10):\n",
        "  print(\"\\n\\n<\", j*5, \"번 이미지> : \")\n",
        "  for i in range(1, 6):\n",
        "    generate_caption(i, unq_valid_imgs.iloc[j*5]['image'])\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZqYeBsdQ126"
      },
      "source": [
        "'''\n",
        "for i in range(1, 6):\n",
        "  generate_caption(i, unq_valid_imgs.iloc[100]['image'])\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYATp-A_Q53S"
      },
      "source": [
        "'''\n",
        "for i in range(1, 6):\n",
        "  generate_caption(i, unq_valid_imgs.iloc[70]['image'])\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKHbClPqySoG"
      },
      "source": [
        "for i in range(1, 6):\n",
        "  generate_caption(i, unq_valid_imgs.iloc[-1]['image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuuMi1uPRDBJ"
      },
      "source": [
        "** test with my images **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIR5DCJdRFNK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}